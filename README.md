# SAL — System of AI Liability

**Author:** Oleksii Poshvaniuk  
**Created:** 2026  
**Status:** Concept / Research / Early Stage  

---

## What is SAL?

SAL (System of AI Liability) is a conceptual framework designed to introduce
responsibility-aware interaction rules between AI agents and humans.

The core idea:
> AI agents should be evaluated not only by performance, but by contextual responsibility,
ethical consistency, and resilience to adversarial interaction.

SAL introduces:
- Responsibility scoring
- Context-aware refusal handling
- Protection against malicious rating attacks
- Long-term trust accumulation between agents

---

## Why it matters

As AI agents scale across marketplaces, platforms, and autonomous environments,
there is currently **no unified responsibility layer** comparable to CAPTCHA or identity verification.

SAL proposes such a layer.

---

## Legal note

This repository documents an original conceptual framework.
All rights reserved to the author unless explicitly licensed.

© Oleksii Poshvaniuk
